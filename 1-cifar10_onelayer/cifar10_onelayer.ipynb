{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "waiting-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, -3, 0], [4, -7, -9, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vocational-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clear-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2, -3,  0],\n",
       "       [ 4, -7, -9,  5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.positive(array)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ordered-blackberry",
   "metadata": {},
   "source": [
    "np.where(array > 0, array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "democratic-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0],\n",
       "       [4, 0, 0, 5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(array > 0, array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-sport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finite-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key='labels'):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "    # Arguments\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "    # Returns\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, 'rb') as f:\n",
    "        if sys.version_info < (3,):\n",
    "            d = pickle.load(f)\n",
    "        else:\n",
    "            d = pickle.load(f, encoding='bytes')\n",
    "            # decode utf8\n",
    "            d_decoded = {}\n",
    "            for k, v in d.items():\n",
    "                d_decoded[k.decode('utf8')] = v\n",
    "            d = d_decoded\n",
    "    data = d['data']\n",
    "    labels = d[label_key]\n",
    "\n",
    "    #data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    data = data.reshape(data.shape[0], 3072)\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valued-foundation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:\t (10000, 3072) \t y_train shape:\t (10000,)\n",
      "x_val shape:\t (10000, 3072) \t y_val shape:\t (10000,)\n",
      "x_test shape:\t (10000, 3072) \t y_test shape:\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "path = 'cifar-10-batches-py'\n",
    "train_fpath = os.path.join('../', path, 'data_batch_1')\n",
    "val_fpath = os.path.join('../', path, 'data_batch_2')\n",
    "test_fpath = os.path.join('../', path, 'test_batch')\n",
    "\n",
    "x_train, y_train = load_batch(train_fpath)\n",
    "x_val, y_val = load_batch(val_fpath)\n",
    "x_test, y_test = load_batch(test_fpath)\n",
    "\n",
    "print('x_train shape:\\t', x_train.shape, '\\t y_train shape:\\t', y_train.shape)\n",
    "print('x_val shape:\\t', x_val.shape, '\\t y_val shape:\\t', y_val.shape)\n",
    "print('x_test shape:\\t', x_test.shape, '\\t y_test shape:\\t', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regulated-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean shape:\t (3072,) \n",
      "std shape:\t (3072,)\n",
      "2.2611542268199023e-18 0.9999999999999997\n",
      "-0.002367710988733489 0.9987174761512392\n",
      "0.007943731845370715 0.995771074950348\n"
     ]
    }
   ],
   "source": [
    "mean, std = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "print('mean shape:\\t', mean.shape, '\\nstd shape:\\t', std.shape)\n",
    "\n",
    "x_train = ( x_train - mean ) / std\n",
    "x_val = ( x_val- mean ) / std\n",
    "x_test = ( x_test - mean ) / std\n",
    "\n",
    "print(x_train.mean(), x_train.std())\n",
    "print(x_val.mean(), x_val.std())\n",
    "print(x_test.mean(), x_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # number of classes\n",
    "\n",
    "W = np.random.normal(0, 0.01, (K, 3072))\n",
    "b = np.random.normal(0, 0.01, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "driving-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\" Standard definition of the softmax function \"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specialized-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(X, W, b):\n",
    "    P = np.zeros((X.shape[0], K))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        P[i] = np.dot(W, X[i]) + b\n",
    "        \n",
    "    return np.array([softmax(x) for x in P])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "identified-cancellation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08790861, 0.02824124, 0.04564345, 0.07911984, 0.10143588,\n",
       "        0.11025037, 0.06123634, 0.05845446, 0.24772125, 0.17998855],\n",
       "       [0.03082081, 0.04021581, 0.16655865, 0.06627206, 0.08107283,\n",
       "        0.07951193, 0.12884459, 0.2054497 , 0.04390658, 0.15734703],\n",
       "       [0.03352015, 0.23399536, 0.08618753, 0.11818484, 0.06456317,\n",
       "        0.09271226, 0.11940725, 0.09990882, 0.10790776, 0.04361286],\n",
       "       [0.07572491, 0.0465474 , 0.08270794, 0.10335497, 0.11270224,\n",
       "        0.223768  , 0.10216423, 0.06196893, 0.08431465, 0.10674673],\n",
       "       [0.03268444, 0.02391992, 0.07574657, 0.06818139, 0.21457276,\n",
       "        0.19544687, 0.05187682, 0.06499631, 0.10796978, 0.16460514]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = evaluate_classifier(x_train[:5], W, b)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "danish-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, Y, W, b, lamb):\n",
    "    \n",
    "    cost = 0\n",
    "\n",
    "    P = evaluate_classifier(X, W, b)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        cost -= np.log(P[i][Y[i]] + sys.float_info.epsilon)\n",
    "    \n",
    "    cost /=  X.shape[0]\n",
    "    \n",
    "    cost += lamb * np.sum(W**2)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "positive-glance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.398557739821925"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb = 0.3\n",
    "compute_cost(x_val, y_val, W, b, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "charitable-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(X, Y, W, b):\n",
    "    \n",
    "    acc = 0\n",
    "    \n",
    "    P = evaluate_classifier(X, W, b)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        if Y[i] == np.argmax(P[i]):\n",
    "            acc += 1\n",
    "            \n",
    "    return acc / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fossil-saturday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.106"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(x_train, y_train, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "extraordinary-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    shape = (Y.size, Y.max()+1)\n",
    "    one_hot = np.zeros(shape)\n",
    "    rows = np.arange(Y.size)\n",
    "    one_hot[rows, Y] = 1\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "voluntary-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, Y, P, W, b, lamda):\n",
    "    \"\"\"\n",
    "    each column of X corresponds to an image and it has size d×n.\n",
    "    each column of Y (K×n) is the one-hot ground truth label for the corresponding column of X.\n",
    "    each column of P contains the probability for each label \n",
    "        for the image in the corresponding column of X. P has size K×n.\n",
    "    @return [grad_W, grad_b]\n",
    "        grad_W is the gradient matrix of the cost J relative to W and has size K×d.\n",
    "        grad_b is the gradient vector of the cost J relative to b and has size K×1.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = X.shape[0]\n",
    "    \n",
    "    g_batch = - (one_hot(Y) - P)\n",
    "    grad_loss_w = 1/batch_size * np.dot(g_batch, X.T)\n",
    "    \n",
    "    grad_w = grad_loss_w + 2*lamda*W\n",
    "    grad_b = 1/batch_size * np.sum((g_batch), axis=1).reshape(-1,1)\n",
    "    \n",
    "    return grad_b, grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accredited-success",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,10) and (3072,100) not aligned: 10 (dim 1) != 3072 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-8f80b0597d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mgrad_w_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-17f4957aa9bc>\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(X, Y, P, W, b, lamda)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mg_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mgrad_loss_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# regularization is added to the weights but not to the bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mgrad_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_loss_w\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (100,10) and (3072,100) not aligned: 10 (dim 1) != 3072 (dim 0)"
     ]
    }
   ],
   "source": [
    "P = evaluate_classifier(x_train[:100], W, b)\n",
    "lamda = 0.1\n",
    "[grad_w_num, grad_b_num] = compute_gradients(x_train[:100], y_train[:100], P, W, b, lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "armed-generic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3072)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "visible-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeGradsNum(X, Y, P, W, b, lamda, h):\n",
    "\t\"\"\" Converted from matlab code \"\"\"\n",
    "\tno \t= \tW.shape[0]\n",
    "\td \t= \tX.shape[0]\n",
    "\n",
    "\tgrad_W = np.zeros(W.shape);\n",
    "\tgrad_b = np.zeros((no, 1));\n",
    "\n",
    "\tc = compute_cost(X, Y, W, b, lamda);\n",
    "\t\n",
    "\tfor i in range(len(b)):\n",
    "\t\tb_try = np.array(b)\n",
    "\t\tb_try[i] += h\n",
    "\t\tc2 = compute_cost(X, Y, W, b_try, lamda)\n",
    "\t\tgrad_b[i] = (c2-c) / h\n",
    "\n",
    "\tfor i in range(W.shape[0]):\n",
    "\t\tfor j in range(W.shape[1]):\n",
    "\t\t\tW_try = np.array(W)\n",
    "\t\t\tW_try[i,j] += h\n",
    "\t\t\tc2 = compute_cost(X, Y, W_try, b, lamda)\n",
    "\t\t\tgrad_W[i,j] = (c2-c) / h\n",
    "\n",
    "\treturn [grad_W, grad_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "boring-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = evaluate_classifier(x_train[:5], W, b)\n",
    "lamda = 0.1\n",
    "[grad_w_num, grad_b_num] = ComputeGradsNum(x_train[:100], y_train[:100], P, W, b, lamda, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confident-window",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "future-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-trading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
